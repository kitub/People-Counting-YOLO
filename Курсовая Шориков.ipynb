{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Трекинг и подсчет пешеходов\n",
    "\n",
    "Использованные библиотеки: ultralytics, supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import supervision as sv\n",
    "from supervision.assets import download_assets, VideoAssets\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people-walking.mp4 asset download complete. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VideoInfo(width=1920, height=1080, fps=25, total_frames=341)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка датасета с идущими людьми\n",
    "\n",
    "video_path = download_assets(VideoAssets.PEOPLE_WALKING) \n",
    "sv.VideoInfo.from_video_path(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание модели YOLOv11 и перенос ее на GPU при возможности\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = YOLO(\"yolo11s.pt\").to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получение идентификатора класса человек в модели YOLO\n",
    "\n",
    "class_names = ['person']\n",
    "id_to_name = model.model.names\n",
    "name_to_id = {k: v for v, k in id_to_name.items()}\n",
    "class_ids = [name_to_id[class_name] for class_name in class_names]\n",
    "class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# информация о видео\n",
    "video_info = sv.VideoInfo.from_video_path(video_path)\n",
    "\n",
    "# Создание ByteTracker для трекинга и подсчета\n",
    "byte_tracker = sv.ByteTrack(\n",
    "    track_activation_threshold=0.2, # порог для распознавания\n",
    "    lost_track_buffer=75, # количество кадров для потери объекта\n",
    "    minimum_matching_threshold=0.7, # порог для принятия второго распознавания того же объекта\n",
    "    frame_rate=video_info.fps, # кадров/сек\n",
    "    minimum_consecutive_frames=3) # минимальное количество кадров для распознавания\n",
    "\n",
    "byte_tracker.reset()\n",
    "\n",
    "# генератор кадров\n",
    "generator = sv.get_video_frames_generator(video_path)\n",
    "\n",
    "# Аннотаторы для аннотации объектов на видео\n",
    "box_annotator = sv.BoxAnnotator(thickness=4)\n",
    "label_annotator = sv.LabelAnnotator(text_thickness=2, text_scale=1.5, text_color=sv.Color.BLACK)\n",
    "trace_annotator = sv.TraceAnnotator(thickness=4, trace_length=50)\n",
    "\n",
    "# callback функция для трекинга и аннотации кадра\n",
    "def callback(frame: np.ndarray, index: int) -> np.ndarray:\n",
    "    # предсказание модели\n",
    "    results = model(frame, verbose=False)[0]\n",
    "    # перевод предсказания в формат supervision detections\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    # выбираем распознавания только нужных классов\n",
    "    detections = detections[np.isin(detections.class_id, class_ids)]\n",
    "    # трекинг с помощью ByteTrack\n",
    "    detections = byte_tracker.update_with_detections(detections)\n",
    "    labels = [\n",
    "        f\"#{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\"\n",
    "        for confidence, class_id, tracker_id\n",
    "        in zip(detections.confidence, detections.class_id, detections.tracker_id)\n",
    "    ]\n",
    "\n",
    "    # аннотация\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = trace_annotator.annotate(\n",
    "        scene=annotated_frame, detections=detections)\n",
    "    annotated_frame = box_annotator.annotate(\n",
    "        scene=annotated_frame, detections=detections)\n",
    "    annotated_frame = label_annotator.annotate(\n",
    "        scene=annotated_frame, detections=detections, labels=labels)\n",
    "\n",
    "    return annotated_frame\n",
    "\n",
    "# обработка видео\n",
    "sv.process_video(\n",
    "    source_path = video_path,\n",
    "    target_path = 'result.mp4',\n",
    "    callback=callback\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
